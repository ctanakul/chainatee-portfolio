<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="shortcut icon" href="../../docs-assets/ico/favicon.png">

    <title>CHAINATEE TANAKULRUNGSON</title>

    <!-- Bootstrap core CSS -->
    <link href="assets/css/bootstrap.css" rel="stylesheet">


    <!-- Custom styles for this template -->
    <link href="assets/css/main.css" rel="stylesheet">

    <script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
    <script src="assets/js/hover.zoom.js"></script>
    <script src="assets/js/hover.zoom.conf.js"></script>

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <!-- Static navbar -->
    <div class="navbar navbar-inverse navbar-static-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="index.html">CHAINATEE TANAKULRUNGSON</a>
        </div>
        <div class="navbar-collapse collapse">
          <ul class="nav navbar-nav navbar-right">
            <li><a href="index.html">Projects</a></li>
            <li><a href="about.html">About</a></li>
            <li><a href="assets/resume.pdf">Resume</a></li>
            <li><a href="contact.html">Contact</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </div>
	
	
	<!-- +++++ Projects Section +++++ -->
	
	<div class="container pt">
		<div class="row mt">
			<div class="col-lg-6 col-lg-offset-3 centered">
			  <h3>SAWYER CATCH'EM ALL</h3>
			  <hr>
			</div>
			<div class="col-lg-6 col-lg-offset-3 centered">
			  <p>&nbsp;</p>
				<p><iframe width="560" height="315" src="https://www.youtube.com/embed/G9JMFI1IMac" frameborder="0" allowfullscreen></iframe></p>
			</div>
			<div class="col-lg-15">
			  <p>&nbsp;</p>
				<p>&nbsp;</p>
                          <p><img class="img-responsive" src="assets/img/portfolio/work06_sawyer_catch_ball_diagram.png" alt=""></p>

			  <p><b><font size="5">Overview</font></b></p>
			  <p><font size="4">The goal of this project is to operate Sawyer, the manufacturing robot by Rethink Robotics, to catch a ball thrown at him. The hardware used are Sawyer and <a href="https://en.wikipedia.org/wiki/Stereo_camera">a stereo camera</a> with RGB and depth sensor. The system functions in 3 main parts: detecting the ball position, predicting the final position of the ball and moving the arm with Jacobian based endpoint control algorithm to catch the ball. The system runs via Robotic Operating System (ROS) with Python scripts.</font></p>

			  <p><b>Part 1: The Ball Detection System</b></p>
	
			  <p>Just like human needs eyes to see objects, Sawyer needs an RGBD camera to detect the position of the ball. Here, we use Asus Xtion Pro run with <a href="http://wiki.ros.org/openni2_launch">openni2</a> package. Together, they can process a stream of RGB and depth images separately. The RGB image is in the form of a multi-dimensional array of type uint8 with three layers of rectangle (with x length y width) specifying the color of each pixel based on RGB. Conversely, the depth image is the matrix of the same type and size but only one layer. The number in each cell of the depth image represents the physical distance of that pixel from the camera frame. For example, the whiter the pixel is, the further the object is from the real camera.</p>
                          <p><img class="img-responsive" src="assets/img/portfolio/work06_rgb_and_depth_img.png" alt=""></p>
			  <p>The left image is an RGB image and the right one is a depth image. Comparatively, the white part of the depth image correlates with the far object such as the wall, while the black part in the bottom left correlates to the robot head close to the camera frame.</p>
			  <p>My strategy for detecting the ball is to get the position of the pixel at the center of the ball in the RGB image (the red dot in the image above), and then perform some processes to know how far the ball is from the camera frame.</p>
			  <p>To get the position of the pixel representing center of the ball in an RGB image, the color of the ball has to be tracked first with OpenCV functions. The ball is then enclosed in a circle, and the center position is recorded.</p>
			  <p>After that, the position is processed through <a href="http://docs.ros.org/api/image_geometry/html/python/#image_geometry.PinholeCameraModel.projectPixelTo3dRay">projectPixelTo3dRay</a> function and the depth scaling process to get the approximated ball position relative to the camera.</p>
			  <p>However, the desired final position needs to be relative to Sawyer not the camera since the camera is not attached to Sawyer.
                          <p><img class="img-responsive" src="assets/img/portfolio/work06_frames.png" alt=""></p>
			  <p>From the image, T represents the transformation matrix describing the position and orientation of a frame relative to the other frame. Correspondingly, P represents the 3x1 matrix describing the relative position between two positions.</p>
			  <p>With matrix multiplication, we can get the position of the ball relative to Sawyer.</p> 

			  <p><b>Part 2: the final position prediction</b></p>
			  <p>The projectile calculating algorithm estimates the future position of the ball by fitting the 3D parabola plot with RANSAC. The plot is being updated through throwing.</p>
			  <p><b>Part 3: Catching the ball with Jacobian based endpoint control algorithm</b></p>
			  <p>Since each throw spends around a second or so, the arm must be moved within a second. Before every move, the hand will be moved to home position.  The <a href="http://math.ucsd.edu/~sbuss/ResearchWeb/ikmethods/iksurvey.pdf#page=9">damped least square inverse kinematics</a> is used to find joint velocity for each joint of the robot arm to place the end-effector at desired point. We need to specify damping constant that is “large enough so that the solutions for joints are well-behaved near singularities, but if it is chosen too large, then the convergence rate is too slow.” This method focuses on minimizing the chance of having the set of joints that move end-effector to the unreachable point. </p>

			  <p><b>Result</b></p>
			  <p>Sawyer can move his hand to the predicted solution. However, his hand needs to move faster than half a second to catch the ball. Possibly, the velocity is clipped down by the factory-set-limit since Sawyer is supposed to be working with human on a factory floor.</p>

<!-- 			  <p>The frequency of published pointcloud is adjusted to be at 30 Hz. The assumed number of 3D positions needed for future position estimation is 5 positions which will take about 15 milliseconds. Since the estimated time used in a throw is about 1 second, the time for the arm to move to catch the ball is about 85 milliseconds. For simplicity, the planar area for moving hand is specified. This area can be found by moving the arm and timing the total time used.<p> -->
<!-- 			  <p>Before every move, the hand will be moved to home position by sending the dictionary containing names and joint positions as a parameter in <a href="http://api.rethinkrobotics.com/baxter_interface/html/baxter_interface.limb.Limb-class.html">move_to_joint_positions</a> function of class Limb. The -->
<!-- <a href="http://web.cse.ohio-state.edu/~parent/classes/694A/Lectures/Material/IKsurvey.pdf">damped least square inverse kinematics</a> is used to find joint velocity for each joint in robot arm while -->
<!-- moving. The damping constant delays time in finding joint solution to avoid singularities. However,high damping constant will slow the convergence time a lot. Joint angular velocities are then -->
<!-- published under the topic of robot/limb/right/joint_command of type<a href="http://api.rethinkrobotics.com/baxter_core_msgs/html/msg/JointCommand.html">intera_core_msgs/JointCommand</a>.</p> -->
<!-- 			  <p>The approximate area that the hand can be moved within 85 milliseconds is 30 x 30 cm square on the right side and a semicircle with 30 cm radius on the left side of the home position.</p> -->

<!-- 			  <p><b>Present development</b></p> -->
<!-- 			  <p>The present challenge is to get the correct 3D position of the ball from pointcloud. Normally, pointcloud can return the 3D position quite accurate. However, for moving object such as a thrown ball, the stereo-correspondence may fail which will return depth of NaN (Non-applicable Number). With NaN depth, the 3D position of the ball cannot be found which lead to the loss of data for trajectory prediction.</p> -->
<!-- 			  <p>However, with the assumption that some pixels around such problematic pixels may not fail in returning depth, the author finds depth of every 30 x 30 pixels around the center and find the average depth of all. Outlier depths which may be returned from those points not being part of a ball such as wall will be filtered out. This process can return depth for every pixel specified as the center of the ball.</p> -->
<!-- 			  <p>To check the accuracy and analyze the data, the coordinate of pixels specified as center of the ball and the 3D position of the ball are <a href="https://github.com/ctanakul/sawyer-catching-ball/blob/master/src/detect_color_full_system.py#L134">plotted through time</a>.</p> -->


			  <!-- <p><b>Solutions</b></p> -->
			  <!-- <p> -->
			  <!--   <ul> -->
			  <!--     <li>Use functions of OpenCV such as GaussianBlur and InRange in HSV spectrum to get the position of the ball</li> -->
			  <!--     <li>Access pointcloud via <a href="https://www.asus.com/us/3D-Sensor/Xtion_PRO_LIVE/">Asus Xtion Pro Live</a> with <a href="http://wiki.ros.org/openni2_launch">openni2</a>, functions of <a href="http://docs.ros.org/api/image_geometry/html/python/#image_geometry.PinholeCameraModel.projectPixelTo3dRay">image_geometry</a> and noise filtering algorithm</li> -->
			  <!--     <li><a href="http://web.cse.ohio-state.edu/~parent/classes/694A/Lectures/Material/IKsurvey.pdf">Use damped least square inverse kinematics</a> to avoid singularities</li> -->
			  <!--   </ul> -->
			  <!-- </p> -->
                          <p><img class="img-responsive" src="assets/img/portfolio/work06_sawyer_catch_ball.gif" alt=""></p>


			  <p><b>Let's see more</b></p>
			  <p><a href="https://github.com/ctanakul/sawyer-catching-ball">Github</a><!-- <a href="https://youtu.be/ngZCMMJjaLA">Youtube</a>, --> <!-- <a href="https://vimeo.com/195121510">Vimeo</a></p> -->


			</div>
		</div>
		<!-- <div class="row mt centered">	 -->
		<!--   <p><iframe width="840" height="472.5" src="https://www.youtube.com/embed/ngZCMMJjaLA" frameborder="0" allowfullscreen></iframe></p> -->
		<!-- </div> -->
		<div class="row mt">
		  <p><b>Acknowledgements</b></p>
		  <p>
		    <ul>
		      <li>Dr.Jarvis A. Schultz, the associate director of Ms in Robotics, Northwestern University</li>
		    </ul>
		  <p>
		</div>

	</div><!-- /container -->
	
	
	<!-- +++++ Footer Section +++++ -->
	
	<div id="footer">
		<div class="container">
			<div class="row">
				<div class="col-lg-4">
				  <h4>Address</h4>
				  <p>
				    2145 Sheridan Rd., Evanston, IL, 60201<br/>
				    <!-- +1 773 865 0534, <br/> -->
				    <!-- Madrid, Spain. -->
				  </p>
				</div><!-- /col-lg-4 -->
				
				<div class="col-lg-4">
					<h4>Links</h4>
					<p>
						<a href="https://github.com/ctanakul">Github</a><br/>
						<a href="https://www.linkedin.com/in/chainatee-tanakulrungson">Linkedin</a><br/>
						<!-- <a href="#">Facebook</a> -->
					</p>
				</div><!-- /col-lg-4 -->
				
				<div class="col-lg-4">
					<h4>E-Mail</h4>
					<p>
						<a href="mailto:cnt.tanakul@gmail.com">cnt.tanakul@gmail.com</a><br/>
					</p>
				</div><!-- /col-lg-4 -->
			
			</div>
		
		</div>
	</div>
	

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="assets/js/bootstrap.min.js"></script>
  </body>
</html>
